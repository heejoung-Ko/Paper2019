# Deterministic Vs Stochastic (nondeterministic)

- In deterministic models : 내가 결정한 방향으로 가는 것, 다음에도 같은 상태에서 같은 방향으로 가면 같은 reward를 받는다. 
  ex) 오른쪽으로 가! -> 오른쪽으로 간다. 
       2의 상태에서 오른쪽으로 가면 항상 1의 reward를 받음.

- Stochastic : 내가 결정한 방향으로 갈 수 도있고 가지 않을 수도있는 것, 같은 상태에서 같은 방향을 선택해도 같은 reward를 받지 않을 수도 있다.
  ex) 오른쪽으로 가! -> 가만히 있는다.
       오른쪽으로 가! -> 오른쪽으로 간다.
       오른쪽으로 가! -> 아래로 간다.
       2의 상태에서 오른쪽으로 가도 1의 reward를 받지 못할 수도 있다.


- 우리가 앞서 구현했던 Q-learning은 Deterministic한 world에서의 Q-algorithm이다.
- Stochastic world 에서 Deterministic world에서 구현한 Q-algorithm을 선택하면 제대로 학습하지 못한다.


## Stochasitc world

- 이곳에서는 Q의 값에 무조건 의존하면 X
- Learning rate (α)값을 정해서 그 만큼만 의존하도록 식을 수정하면 된다!

- 기존의 식 : Q(s, a) ← r + γ maxQ(s', a')
- 수정된 식 : Q(s, a) ← (1 - α)Q(s, a) + α [ r + γ maxQ(s', a') ]
	 = Q(s, a) ← Q(s, a) + α [ r + γ maxQ(s', a') - Q(s, a)]

* * *

# Q-learning algorithm

1. Q-table을 0으로 초기화한다.
2. 현재 상태 s를 받아온다.
(3 ~ 6을 반복한다.)
3. E&E(expolit & exploration)를 통해 행동 a를 선택한다.
4. 그에 따른 리워드 r과 새로운 상태가 될 s'를 받아온다.
5. 식을 통해 Q의 값을 갱신한다. : Q(s, a) ← (1 - α)Q(s, a) + α [ r + γ maxQ(s', a') ]
6. 현재 상태를 다음의 상태로 바꾼다. s ← s'

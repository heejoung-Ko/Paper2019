Lec 07

Q Network가 잘 학습되지 않는 이유
1) sample들 사이의 상호관계 
: 일부 sample로만 학습시킬 시 최종적인 모델과 전혀 다른 모델이 나올 가능성
2) target(실제 Y 값)이 흔들림
: 예측 값이 target에 맞게 업데이트 할 때 target도 함께 움직임

DQN의 해결책
1) go deep: 깊게 가기
2) sample들 사이의 상호관계 해결 -> experience replay
: 바로 학습하지 말고 버퍼에 저장 -> 버퍼에서 랜덤하게 가져와서 학습
3) target이 흔들림 -> 네트워크 하나 더 만들기
min ∑ [Q^(s t, a t|θ) - (r t + γmaxQ^(s t+1, a'|θ"))]2
θ만 업데이트, θ"는 시간이 지난 후 θ를 카피

